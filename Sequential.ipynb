{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequential.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMvDA281yr5D7kLxJtsfZRG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfink09/Deep-Learning/blob/Sequential-Models/Sequential.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wlhxWJlxA-1p"
      },
      "outputs": [],
      "source": [
        "# For the sequential model, import Sequential and Dense\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential models have a single input and a single output\n",
        "# The first numbers in the Dense() is the number of units/neurons\n",
        "# The input shape of 784 specifies 784 elements\n",
        "\n",
        "model = Sequential([\n",
        "     Dense(32,activation=\"relu\",input_shape=(784,)),        \n",
        "     Dense(10,activation=\"softmax\"),               \n",
        "])\n",
        "\n",
        "# Display the model\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuuF212FB03o",
        "outputId": "de052eac-8856-4521-9a9a-45399e7ee51e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential model build with .add() to add layers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(32,activation=\"relu\",input_shape=(784,)))\n",
        "model.add(Dense(10,activation=\"softmax\"))\n",
        "\n",
        "# Displays the same model\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPklO353jpNw",
        "outputId": "dd181d6a-6517-438d-f6e7-9d83a218ca55"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can use either input_shape() or input_dim\n",
        "\n",
        "# input layer is a tensor, not a layer. It is the starting tensor sent to the first hidden layer. \n",
        "# The starting tensor needs to have the same shape as the training data.\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=32, activation=\"relu\", input_shape=(784,))) # Do not need to use units=, can use only the value for number of neurons\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb_VAw2Mk96e",
        "outputId": "72af3b9b-528e-4022-df52-4778948d56ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 32)                25120     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,120\n",
            "Trainable params: 25,120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input_dim has only one dimension (scalar number, number of elements), it does not need to be a tuple. \n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(32, activation=\"relu\", input_dim=784))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH8nzLjWlN3X",
        "outputId": "84525163-592f-496c-d204-b5e956c0963a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_13 (Dense)            (None, 32)                25120     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,120\n",
            "Trainable params: 25,120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Before the model is trained, a learning process is configured with the compile method.\n",
        "# The compile method takes in three arguments (an optimizer, a loss function, and a list of metrics).\n",
        "# The optimizer can be a string identifier of an existing optimizer like rmsprop or adagrad or an instance of an Optimizer class.\n",
        "# The loss function is the function that the model tries to minimize. \n",
        "# The loss function can be a string identifier of an existing loss function like categorial_crossentropy or mse or an objective function.\n",
        "# For any classification problem, set the list of metrics to metrics=[\"accuracy\"]. It can be the string identifier of an existing metric or a custom metric function.\n",
        "# Optimizers and losses are always needed for learning, but metrics are not always required.\n",
        "\n",
        "# For multi-class classification problems\n",
        "model.compile(optimizer=\"rmsprop\",loss=\"categorial_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "# For binary classification problems\n",
        "model.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "# For mean squared error regression problems\n",
        "model.compile(optimizer=\"rmsprop\",loss=\"mse\")\n",
        "\n",
        "# For custom metrics\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "def mean_pred(y_true,y_pred):\n",
        "  return K.mean(y_pred)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"accuracy\",mean_pred])\n"
      ],
      "metadata": {
        "id": "SMceWu_SuTnS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "# Keras models are trained on NumPy arrays of input data and labels\n",
        "# Can use three models fit function, fit_generator, train_on_batch\n",
        "# fit function is basic \n",
        "# fit_generator for large datasets which takes in a generator instead of a NumPy array, \n",
        "# train_on_batch for a single gradient update over one batch of samples.\n",
        "\n",
        "# Make a model\n",
        "model = Sequential()\n",
        "\n",
        "# Add layers\n",
        "model.add(Dense(32,activation=\"relu\",input_dim=100))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "# Generate dummy data\n",
        "import numpy as np\n",
        "data = np.random.random((1000,100)) # 100 dimensions since the input_dim is 100 dimensions\n",
        "labels = np.random.randint(2,size=(1000,1)) # Target must be 0D or 1D since the loss is binary\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaZg7TBnxUYV",
        "outputId": "76a2aae4-972e-44d1-8795-8c4455d4b6d2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 32)                3232      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,265\n",
            "Trainable params: 3,265\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit?"
      ],
      "metadata": {
        "id": "UqKoVTGkzJHV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model (in general the loss goes down with each epoch)\n",
        "\n",
        "model.fit(\n",
        "    data,\n",
        "    labels,\n",
        "    batch_size=32,        # Number of examples we train in tandem\n",
        "    epochs=10,            # Number of times we go through the dataset. Number of samples we go through = number of samples * number of epochs (100*10=1000 samples if data=100)\n",
        "    verbose=2,            # If 1 shows progress bar, if 2 skips progress bar\n",
        "    callbacks=None,\n",
        "    validation_split=0.2, # Split our data such that 0.2 of it is for validation\n",
        "    validation_data=None, # External source for validation specified\n",
        "    shuffle=True,         # Always important to shuffle data for algorithms\n",
        "    class_weight=None,    # Important to specify if weights are not balanced\n",
        "    sample_weight=None,   # Weight for each sample\n",
        "    initial_epoch=0)      # Start epoch at a different time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7YfG2Fwz2r5",
        "outputId": "ae9345f9-1b98-4628-ce2d-f3c2dba5fb23"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 - 1s - loss: 0.7182 - accuracy: 0.5025 - val_loss: 0.6981 - val_accuracy: 0.5350 - 999ms/epoch - 40ms/step\n",
            "Epoch 2/10\n",
            "25/25 - 0s - loss: 0.7064 - accuracy: 0.5000 - val_loss: 0.6881 - val_accuracy: 0.5550 - 77ms/epoch - 3ms/step\n",
            "Epoch 3/10\n",
            "25/25 - 0s - loss: 0.6970 - accuracy: 0.5387 - val_loss: 0.6862 - val_accuracy: 0.5750 - 67ms/epoch - 3ms/step\n",
            "Epoch 4/10\n",
            "25/25 - 0s - loss: 0.6896 - accuracy: 0.5400 - val_loss: 0.6881 - val_accuracy: 0.5500 - 79ms/epoch - 3ms/step\n",
            "Epoch 5/10\n",
            "25/25 - 0s - loss: 0.6808 - accuracy: 0.5612 - val_loss: 0.6918 - val_accuracy: 0.5400 - 79ms/epoch - 3ms/step\n",
            "Epoch 6/10\n",
            "25/25 - 0s - loss: 0.6810 - accuracy: 0.5537 - val_loss: 0.6918 - val_accuracy: 0.5400 - 82ms/epoch - 3ms/step\n",
            "Epoch 7/10\n",
            "25/25 - 0s - loss: 0.6736 - accuracy: 0.5900 - val_loss: 0.7033 - val_accuracy: 0.5200 - 71ms/epoch - 3ms/step\n",
            "Epoch 8/10\n",
            "25/25 - 0s - loss: 0.6696 - accuracy: 0.5900 - val_loss: 0.6954 - val_accuracy: 0.5400 - 80ms/epoch - 3ms/step\n",
            "Epoch 9/10\n",
            "25/25 - 0s - loss: 0.6625 - accuracy: 0.5950 - val_loss: 0.6982 - val_accuracy: 0.5150 - 82ms/epoch - 3ms/step\n",
            "Epoch 10/10\n",
            "25/25 - 0s - loss: 0.6595 - accuracy: 0.5913 - val_loss: 0.7022 - val_accuracy: 0.5300 - 66ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36df968490>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The model will continue training where it left off\n",
        "model.train_on_batch(\n",
        "    data[:32],\n",
        "    labels[:32],\n",
        "    class_weight=None,\n",
        "    sample_weight=None,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY6QOP1C2Ra5",
        "outputId": "8cb12382-4aaa-4e9b-8d59-08ad97c2bd05"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6629115343093872, 0.65625]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator():\n",
        "  for datum, label in zip(data,labels):\n",
        "    yield datum[None,:], label"
      ],
      "metadata": {
        "id": "K5UjPovC2rzj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the fit_generator() method\n",
        "model.fit_generator(\n",
        "    data_generator(),\n",
        "    steps_per_epoch=900,\n",
        "    epochs=1,\n",
        "    verbose=1,\n",
        "    callbacks=None,\n",
        "    validation_data=None, # Can be a generator or a dataset\n",
        "    validation_steps=None,\n",
        "    class_weight=None,\n",
        "    max_queue_size=10,\n",
        "    workers=1,\n",
        "    initial_epoch=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr8gXNTA29C_",
        "outputId": "2327e5bb-28d8-4f6f-f7d0-5d18fa96f4f2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900/900 [==============================] - 3s 3ms/step - loss: 0.6886 - accuracy: 0.5700\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36df962110>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.evaluate(\n",
        "    data,\n",
        "    labels,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    sample_weight=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNKDkWdL4rLd",
        "outputId": "1408318e-2a82-4a25-df1d-97b057536d5c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.5070\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7247481942176819, 0.5070000290870667]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "model.predict(\n",
        "    data,\n",
        "    batch_size=32,\n",
        "    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0ltzMiw45kB",
        "outputId": "ea354cfa-1dc7-4007-ed38-bf5228b980dc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7864026 ],\n",
              "       [0.69827133],\n",
              "       [0.53242046],\n",
              "       [0.5104215 ],\n",
              "       [0.7048656 ],\n",
              "       [0.6373776 ],\n",
              "       [0.7592614 ],\n",
              "       [0.7716632 ],\n",
              "       [0.6008019 ],\n",
              "       [0.6456653 ],\n",
              "       [0.57893085],\n",
              "       [0.75282824],\n",
              "       [0.58368903],\n",
              "       [0.68663037],\n",
              "       [0.70781195],\n",
              "       [0.49395594],\n",
              "       [0.76973796],\n",
              "       [0.5871243 ],\n",
              "       [0.6359753 ],\n",
              "       [0.6579037 ],\n",
              "       [0.7895489 ],\n",
              "       [0.7856277 ],\n",
              "       [0.5999887 ],\n",
              "       [0.5554107 ],\n",
              "       [0.588842  ],\n",
              "       [0.68532234],\n",
              "       [0.66433513],\n",
              "       [0.58200276],\n",
              "       [0.59148806],\n",
              "       [0.6057607 ],\n",
              "       [0.7717278 ],\n",
              "       [0.6167316 ],\n",
              "       [0.6945719 ],\n",
              "       [0.49663085],\n",
              "       [0.59964037],\n",
              "       [0.6608875 ],\n",
              "       [0.5521373 ],\n",
              "       [0.7464306 ],\n",
              "       [0.5697183 ],\n",
              "       [0.75203276],\n",
              "       [0.7643008 ],\n",
              "       [0.52242833],\n",
              "       [0.72067916],\n",
              "       [0.64786315],\n",
              "       [0.7257671 ],\n",
              "       [0.74064004],\n",
              "       [0.6852565 ],\n",
              "       [0.5802776 ],\n",
              "       [0.43770555],\n",
              "       [0.6659745 ],\n",
              "       [0.6930816 ],\n",
              "       [0.5918463 ],\n",
              "       [0.56518096],\n",
              "       [0.523041  ],\n",
              "       [0.57971954],\n",
              "       [0.73907155],\n",
              "       [0.66046214],\n",
              "       [0.65885264],\n",
              "       [0.5140465 ],\n",
              "       [0.5945131 ],\n",
              "       [0.6553476 ],\n",
              "       [0.60933524],\n",
              "       [0.50521094],\n",
              "       [0.53890556],\n",
              "       [0.5402236 ],\n",
              "       [0.74210304],\n",
              "       [0.6953645 ],\n",
              "       [0.71566427],\n",
              "       [0.6098859 ],\n",
              "       [0.5518472 ],\n",
              "       [0.6108293 ],\n",
              "       [0.6421283 ],\n",
              "       [0.54286367],\n",
              "       [0.7545526 ],\n",
              "       [0.57219076],\n",
              "       [0.67883575],\n",
              "       [0.6492789 ],\n",
              "       [0.74269176],\n",
              "       [0.60120416],\n",
              "       [0.6778752 ],\n",
              "       [0.67098653],\n",
              "       [0.59048694],\n",
              "       [0.6251806 ],\n",
              "       [0.6446204 ],\n",
              "       [0.72731066],\n",
              "       [0.5722929 ],\n",
              "       [0.7481258 ],\n",
              "       [0.7091066 ],\n",
              "       [0.6445318 ],\n",
              "       [0.5149502 ],\n",
              "       [0.7747909 ],\n",
              "       [0.81625295],\n",
              "       [0.65823644],\n",
              "       [0.60400945],\n",
              "       [0.77457666],\n",
              "       [0.6841006 ],\n",
              "       [0.6965645 ],\n",
              "       [0.7094063 ],\n",
              "       [0.71076167],\n",
              "       [0.7255806 ],\n",
              "       [0.6686834 ],\n",
              "       [0.6875141 ],\n",
              "       [0.650276  ],\n",
              "       [0.681268  ],\n",
              "       [0.70768404],\n",
              "       [0.54374677],\n",
              "       [0.6996573 ],\n",
              "       [0.59908915],\n",
              "       [0.7171377 ],\n",
              "       [0.6967919 ],\n",
              "       [0.72169614],\n",
              "       [0.7629994 ],\n",
              "       [0.6068134 ],\n",
              "       [0.53623325],\n",
              "       [0.6520608 ],\n",
              "       [0.4946366 ],\n",
              "       [0.7383286 ],\n",
              "       [0.6814708 ],\n",
              "       [0.67379653],\n",
              "       [0.71632576],\n",
              "       [0.6585468 ],\n",
              "       [0.8126606 ],\n",
              "       [0.6145058 ],\n",
              "       [0.69580126],\n",
              "       [0.5680369 ],\n",
              "       [0.735633  ],\n",
              "       [0.71017253],\n",
              "       [0.7813426 ],\n",
              "       [0.50030375],\n",
              "       [0.73163867],\n",
              "       [0.55105275],\n",
              "       [0.6594381 ],\n",
              "       [0.65071225],\n",
              "       [0.643213  ],\n",
              "       [0.58314383],\n",
              "       [0.6349627 ],\n",
              "       [0.6366457 ],\n",
              "       [0.6180942 ],\n",
              "       [0.67700005],\n",
              "       [0.6491543 ],\n",
              "       [0.6364065 ],\n",
              "       [0.48820934],\n",
              "       [0.66208994],\n",
              "       [0.7527902 ],\n",
              "       [0.60567063],\n",
              "       [0.679098  ],\n",
              "       [0.6417917 ],\n",
              "       [0.60566103],\n",
              "       [0.6475537 ],\n",
              "       [0.73861134],\n",
              "       [0.59440464],\n",
              "       [0.7202641 ],\n",
              "       [0.80398357],\n",
              "       [0.755249  ],\n",
              "       [0.6057297 ],\n",
              "       [0.71450895],\n",
              "       [0.7680698 ],\n",
              "       [0.64593405],\n",
              "       [0.7589367 ],\n",
              "       [0.5367319 ],\n",
              "       [0.7080507 ],\n",
              "       [0.61698353],\n",
              "       [0.66151613],\n",
              "       [0.55024225],\n",
              "       [0.7262565 ],\n",
              "       [0.80379224],\n",
              "       [0.7066034 ],\n",
              "       [0.57592106],\n",
              "       [0.69851047],\n",
              "       [0.4461251 ],\n",
              "       [0.722542  ],\n",
              "       [0.75222063],\n",
              "       [0.6405533 ],\n",
              "       [0.6064924 ],\n",
              "       [0.6873724 ],\n",
              "       [0.65621877],\n",
              "       [0.5477832 ],\n",
              "       [0.70995957],\n",
              "       [0.6824541 ],\n",
              "       [0.7477348 ],\n",
              "       [0.58481556],\n",
              "       [0.51924187],\n",
              "       [0.6029304 ],\n",
              "       [0.6334066 ],\n",
              "       [0.77381337],\n",
              "       [0.5469911 ],\n",
              "       [0.7236005 ],\n",
              "       [0.75183916],\n",
              "       [0.6118487 ],\n",
              "       [0.52265143],\n",
              "       [0.61754316],\n",
              "       [0.6382559 ],\n",
              "       [0.46764573],\n",
              "       [0.770185  ],\n",
              "       [0.6694064 ],\n",
              "       [0.63229823],\n",
              "       [0.6593345 ],\n",
              "       [0.67059404],\n",
              "       [0.6613288 ],\n",
              "       [0.61758715],\n",
              "       [0.5981709 ],\n",
              "       [0.45321313],\n",
              "       [0.7395752 ],\n",
              "       [0.6047152 ],\n",
              "       [0.7258286 ],\n",
              "       [0.7185119 ],\n",
              "       [0.80705905],\n",
              "       [0.78829837],\n",
              "       [0.69537866],\n",
              "       [0.64859855],\n",
              "       [0.5857251 ],\n",
              "       [0.6617067 ],\n",
              "       [0.6934349 ],\n",
              "       [0.752128  ],\n",
              "       [0.6345525 ],\n",
              "       [0.6749213 ],\n",
              "       [0.5228883 ],\n",
              "       [0.5655577 ],\n",
              "       [0.73290014],\n",
              "       [0.6120145 ],\n",
              "       [0.748296  ],\n",
              "       [0.79189885],\n",
              "       [0.7238811 ],\n",
              "       [0.6423192 ],\n",
              "       [0.71572083],\n",
              "       [0.7019854 ],\n",
              "       [0.65045315],\n",
              "       [0.6842012 ],\n",
              "       [0.62508476],\n",
              "       [0.7020577 ],\n",
              "       [0.7031322 ],\n",
              "       [0.609589  ],\n",
              "       [0.7334576 ],\n",
              "       [0.62410486],\n",
              "       [0.6578363 ],\n",
              "       [0.6780811 ],\n",
              "       [0.7069895 ],\n",
              "       [0.7859987 ],\n",
              "       [0.629284  ],\n",
              "       [0.7309866 ],\n",
              "       [0.61892676],\n",
              "       [0.634247  ],\n",
              "       [0.6518045 ],\n",
              "       [0.5532713 ],\n",
              "       [0.71862733],\n",
              "       [0.6918886 ],\n",
              "       [0.66243553],\n",
              "       [0.6916362 ],\n",
              "       [0.6377107 ],\n",
              "       [0.59160745],\n",
              "       [0.48668134],\n",
              "       [0.720356  ],\n",
              "       [0.5695409 ],\n",
              "       [0.5188649 ],\n",
              "       [0.47256407],\n",
              "       [0.66691023],\n",
              "       [0.64256227],\n",
              "       [0.82498527],\n",
              "       [0.6382677 ],\n",
              "       [0.7510064 ],\n",
              "       [0.70625335],\n",
              "       [0.7057907 ],\n",
              "       [0.63497865],\n",
              "       [0.6307983 ],\n",
              "       [0.52844906],\n",
              "       [0.7096569 ],\n",
              "       [0.75555277],\n",
              "       [0.56852984],\n",
              "       [0.5986575 ],\n",
              "       [0.5861705 ],\n",
              "       [0.7750075 ],\n",
              "       [0.53523314],\n",
              "       [0.47947803],\n",
              "       [0.5201976 ],\n",
              "       [0.5691344 ],\n",
              "       [0.5525996 ],\n",
              "       [0.7234717 ],\n",
              "       [0.6861677 ],\n",
              "       [0.4788426 ],\n",
              "       [0.6777274 ],\n",
              "       [0.62982833],\n",
              "       [0.57674956],\n",
              "       [0.7364805 ],\n",
              "       [0.75538695],\n",
              "       [0.6259886 ],\n",
              "       [0.65770984],\n",
              "       [0.6714129 ],\n",
              "       [0.76542205],\n",
              "       [0.67387855],\n",
              "       [0.5078074 ],\n",
              "       [0.69697267],\n",
              "       [0.8551754 ],\n",
              "       [0.52556264],\n",
              "       [0.7212639 ],\n",
              "       [0.5199486 ],\n",
              "       [0.676187  ],\n",
              "       [0.6266426 ],\n",
              "       [0.64276576],\n",
              "       [0.5807557 ],\n",
              "       [0.65323365],\n",
              "       [0.6783736 ],\n",
              "       [0.6303044 ],\n",
              "       [0.5065752 ],\n",
              "       [0.7199939 ],\n",
              "       [0.78302395],\n",
              "       [0.6395291 ],\n",
              "       [0.7116346 ],\n",
              "       [0.76456213],\n",
              "       [0.6270534 ],\n",
              "       [0.7573589 ],\n",
              "       [0.6778687 ],\n",
              "       [0.71294856],\n",
              "       [0.69020385],\n",
              "       [0.82956827],\n",
              "       [0.74116397],\n",
              "       [0.7933403 ],\n",
              "       [0.5351814 ],\n",
              "       [0.60126144],\n",
              "       [0.5862467 ],\n",
              "       [0.7019122 ],\n",
              "       [0.6628214 ],\n",
              "       [0.64163935],\n",
              "       [0.6447482 ],\n",
              "       [0.62124926],\n",
              "       [0.71111375],\n",
              "       [0.7338537 ],\n",
              "       [0.56095695],\n",
              "       [0.70587915],\n",
              "       [0.7897146 ],\n",
              "       [0.71969455],\n",
              "       [0.74887925],\n",
              "       [0.6528721 ],\n",
              "       [0.6953707 ],\n",
              "       [0.6127338 ],\n",
              "       [0.7296506 ],\n",
              "       [0.5973642 ],\n",
              "       [0.75739545],\n",
              "       [0.70211005],\n",
              "       [0.642529  ],\n",
              "       [0.62981725],\n",
              "       [0.645864  ],\n",
              "       [0.7358506 ],\n",
              "       [0.6139673 ],\n",
              "       [0.6347401 ],\n",
              "       [0.64978564],\n",
              "       [0.6945983 ],\n",
              "       [0.44595057],\n",
              "       [0.50428617],\n",
              "       [0.6570392 ],\n",
              "       [0.7347965 ],\n",
              "       [0.66856194],\n",
              "       [0.6396898 ],\n",
              "       [0.73592705],\n",
              "       [0.84757304],\n",
              "       [0.7130865 ],\n",
              "       [0.6106283 ],\n",
              "       [0.722947  ],\n",
              "       [0.532531  ],\n",
              "       [0.49793938],\n",
              "       [0.6517626 ],\n",
              "       [0.72438514],\n",
              "       [0.701099  ],\n",
              "       [0.5591213 ],\n",
              "       [0.65917563],\n",
              "       [0.7048969 ],\n",
              "       [0.6437245 ],\n",
              "       [0.562798  ],\n",
              "       [0.6003786 ],\n",
              "       [0.33229288],\n",
              "       [0.7695442 ],\n",
              "       [0.57875997],\n",
              "       [0.81359917],\n",
              "       [0.68481475],\n",
              "       [0.69245833],\n",
              "       [0.7255633 ],\n",
              "       [0.7576457 ],\n",
              "       [0.644537  ],\n",
              "       [0.5863181 ],\n",
              "       [0.7474211 ],\n",
              "       [0.76038975],\n",
              "       [0.62308097],\n",
              "       [0.5811636 ],\n",
              "       [0.55605465],\n",
              "       [0.65038407],\n",
              "       [0.8170701 ],\n",
              "       [0.5180568 ],\n",
              "       [0.61908317],\n",
              "       [0.71028805],\n",
              "       [0.66040224],\n",
              "       [0.5658344 ],\n",
              "       [0.707788  ],\n",
              "       [0.58088124],\n",
              "       [0.680531  ],\n",
              "       [0.57954997],\n",
              "       [0.760389  ],\n",
              "       [0.73497355],\n",
              "       [0.8371744 ],\n",
              "       [0.72365046],\n",
              "       [0.6945158 ],\n",
              "       [0.6409388 ],\n",
              "       [0.7583957 ],\n",
              "       [0.5191946 ],\n",
              "       [0.77368885],\n",
              "       [0.6860502 ],\n",
              "       [0.6474451 ],\n",
              "       [0.59566635],\n",
              "       [0.65741843],\n",
              "       [0.6777218 ],\n",
              "       [0.59737086],\n",
              "       [0.6580935 ],\n",
              "       [0.7041783 ],\n",
              "       [0.6739324 ],\n",
              "       [0.6606462 ],\n",
              "       [0.6556556 ],\n",
              "       [0.5083868 ],\n",
              "       [0.5643995 ],\n",
              "       [0.8139013 ],\n",
              "       [0.76747096],\n",
              "       [0.6595703 ],\n",
              "       [0.73866636],\n",
              "       [0.58137476],\n",
              "       [0.52865595],\n",
              "       [0.62016106],\n",
              "       [0.58182627],\n",
              "       [0.64465594],\n",
              "       [0.6911315 ],\n",
              "       [0.7032258 ],\n",
              "       [0.660493  ],\n",
              "       [0.61547154],\n",
              "       [0.72497   ],\n",
              "       [0.4740693 ],\n",
              "       [0.65587914],\n",
              "       [0.62369823],\n",
              "       [0.5858505 ],\n",
              "       [0.8004147 ],\n",
              "       [0.7406886 ],\n",
              "       [0.62617314],\n",
              "       [0.61426103],\n",
              "       [0.6622802 ],\n",
              "       [0.5992995 ],\n",
              "       [0.7245133 ],\n",
              "       [0.54886496],\n",
              "       [0.68306416],\n",
              "       [0.5034045 ],\n",
              "       [0.65178776],\n",
              "       [0.6080111 ],\n",
              "       [0.6711194 ],\n",
              "       [0.66193944],\n",
              "       [0.5813669 ],\n",
              "       [0.674302  ],\n",
              "       [0.5286889 ],\n",
              "       [0.705518  ],\n",
              "       [0.6261399 ],\n",
              "       [0.6145296 ],\n",
              "       [0.6490651 ],\n",
              "       [0.6115291 ],\n",
              "       [0.5215309 ],\n",
              "       [0.64608777],\n",
              "       [0.69818807],\n",
              "       [0.48518005],\n",
              "       [0.6957953 ],\n",
              "       [0.58094174],\n",
              "       [0.5949248 ],\n",
              "       [0.6272459 ],\n",
              "       [0.59173775],\n",
              "       [0.7167983 ],\n",
              "       [0.67568433],\n",
              "       [0.7292682 ],\n",
              "       [0.67564964],\n",
              "       [0.77293444],\n",
              "       [0.7533129 ],\n",
              "       [0.77157474],\n",
              "       [0.572545  ],\n",
              "       [0.7558819 ],\n",
              "       [0.74011976],\n",
              "       [0.7215    ],\n",
              "       [0.6490392 ],\n",
              "       [0.67536813],\n",
              "       [0.7882192 ],\n",
              "       [0.6440817 ],\n",
              "       [0.34258047],\n",
              "       [0.6031232 ],\n",
              "       [0.675381  ],\n",
              "       [0.6596025 ],\n",
              "       [0.6644353 ],\n",
              "       [0.8395494 ],\n",
              "       [0.69639397],\n",
              "       [0.6340465 ],\n",
              "       [0.68839717],\n",
              "       [0.562587  ],\n",
              "       [0.7010309 ],\n",
              "       [0.7669034 ],\n",
              "       [0.6864152 ],\n",
              "       [0.7324275 ],\n",
              "       [0.7766061 ],\n",
              "       [0.56343055],\n",
              "       [0.61496884],\n",
              "       [0.6615386 ],\n",
              "       [0.6874443 ],\n",
              "       [0.7294557 ],\n",
              "       [0.8187782 ],\n",
              "       [0.7775161 ],\n",
              "       [0.5512129 ],\n",
              "       [0.7077503 ],\n",
              "       [0.646494  ],\n",
              "       [0.5493071 ],\n",
              "       [0.74993175],\n",
              "       [0.6022432 ],\n",
              "       [0.57337487],\n",
              "       [0.5929439 ],\n",
              "       [0.622946  ],\n",
              "       [0.5878474 ],\n",
              "       [0.74643   ],\n",
              "       [0.7017321 ],\n",
              "       [0.6686348 ],\n",
              "       [0.4831907 ],\n",
              "       [0.51122564],\n",
              "       [0.5347681 ],\n",
              "       [0.5889505 ],\n",
              "       [0.68315506],\n",
              "       [0.6867605 ],\n",
              "       [0.5611853 ],\n",
              "       [0.5733871 ],\n",
              "       [0.81121707],\n",
              "       [0.59265655],\n",
              "       [0.5695311 ],\n",
              "       [0.64175594],\n",
              "       [0.6774648 ],\n",
              "       [0.5734495 ],\n",
              "       [0.55016917],\n",
              "       [0.7497407 ],\n",
              "       [0.57617855],\n",
              "       [0.651657  ],\n",
              "       [0.6707078 ],\n",
              "       [0.6368165 ],\n",
              "       [0.7572266 ],\n",
              "       [0.5697782 ],\n",
              "       [0.6637739 ],\n",
              "       [0.6590285 ],\n",
              "       [0.52552354],\n",
              "       [0.5319659 ],\n",
              "       [0.69519377],\n",
              "       [0.7210704 ],\n",
              "       [0.45712045],\n",
              "       [0.6971478 ],\n",
              "       [0.52339613],\n",
              "       [0.71209973],\n",
              "       [0.66832596],\n",
              "       [0.64972997],\n",
              "       [0.77294594],\n",
              "       [0.6933356 ],\n",
              "       [0.698885  ],\n",
              "       [0.5842707 ],\n",
              "       [0.68990433],\n",
              "       [0.6325854 ],\n",
              "       [0.54624695],\n",
              "       [0.6696663 ],\n",
              "       [0.6519157 ],\n",
              "       [0.58555096],\n",
              "       [0.729662  ],\n",
              "       [0.62875885],\n",
              "       [0.67527944],\n",
              "       [0.59703803],\n",
              "       [0.6244287 ],\n",
              "       [0.5382421 ],\n",
              "       [0.72143763],\n",
              "       [0.6643432 ],\n",
              "       [0.6036091 ],\n",
              "       [0.7065958 ],\n",
              "       [0.70342517],\n",
              "       [0.5529409 ],\n",
              "       [0.78623086],\n",
              "       [0.67219245],\n",
              "       [0.8429009 ],\n",
              "       [0.8114737 ],\n",
              "       [0.7722466 ],\n",
              "       [0.5502185 ],\n",
              "       [0.7040603 ],\n",
              "       [0.6856541 ],\n",
              "       [0.7396209 ],\n",
              "       [0.62147176],\n",
              "       [0.65698653],\n",
              "       [0.6753222 ],\n",
              "       [0.65978634],\n",
              "       [0.7838981 ],\n",
              "       [0.6963719 ],\n",
              "       [0.62086415],\n",
              "       [0.6520766 ],\n",
              "       [0.73148   ],\n",
              "       [0.6511319 ],\n",
              "       [0.7748904 ],\n",
              "       [0.67723167],\n",
              "       [0.719859  ],\n",
              "       [0.5443173 ],\n",
              "       [0.67625153],\n",
              "       [0.766278  ],\n",
              "       [0.7515247 ],\n",
              "       [0.6276609 ],\n",
              "       [0.7818872 ],\n",
              "       [0.68153363],\n",
              "       [0.63047737],\n",
              "       [0.63145256],\n",
              "       [0.85617566],\n",
              "       [0.66391337],\n",
              "       [0.7607814 ],\n",
              "       [0.6280042 ],\n",
              "       [0.6794776 ],\n",
              "       [0.661697  ],\n",
              "       [0.5690729 ],\n",
              "       [0.6137817 ],\n",
              "       [0.6827148 ],\n",
              "       [0.532219  ],\n",
              "       [0.702882  ],\n",
              "       [0.4928927 ],\n",
              "       [0.6536734 ],\n",
              "       [0.5209189 ],\n",
              "       [0.75664806],\n",
              "       [0.70725864],\n",
              "       [0.68443596],\n",
              "       [0.6808049 ],\n",
              "       [0.6956348 ],\n",
              "       [0.6174562 ],\n",
              "       [0.6571014 ],\n",
              "       [0.724202  ],\n",
              "       [0.59347916],\n",
              "       [0.70578235],\n",
              "       [0.44854632],\n",
              "       [0.60363054],\n",
              "       [0.7273505 ],\n",
              "       [0.7199489 ],\n",
              "       [0.55508214],\n",
              "       [0.5894505 ],\n",
              "       [0.7267578 ],\n",
              "       [0.6364894 ],\n",
              "       [0.72155386],\n",
              "       [0.7562503 ],\n",
              "       [0.6341307 ],\n",
              "       [0.611523  ],\n",
              "       [0.74934393],\n",
              "       [0.6227164 ],\n",
              "       [0.7330737 ],\n",
              "       [0.62379086],\n",
              "       [0.71982694],\n",
              "       [0.6993955 ],\n",
              "       [0.60017735],\n",
              "       [0.48620495],\n",
              "       [0.60717636],\n",
              "       [0.6512027 ],\n",
              "       [0.6492691 ],\n",
              "       [0.7465044 ],\n",
              "       [0.7499777 ],\n",
              "       [0.6258621 ],\n",
              "       [0.66764754],\n",
              "       [0.54266936],\n",
              "       [0.6981361 ],\n",
              "       [0.6899651 ],\n",
              "       [0.7029589 ],\n",
              "       [0.60509294],\n",
              "       [0.59473956],\n",
              "       [0.5654145 ],\n",
              "       [0.66070384],\n",
              "       [0.53214884],\n",
              "       [0.4744634 ],\n",
              "       [0.646428  ],\n",
              "       [0.5233049 ],\n",
              "       [0.7179055 ],\n",
              "       [0.6213266 ],\n",
              "       [0.5095681 ],\n",
              "       [0.50746566],\n",
              "       [0.6783458 ],\n",
              "       [0.75425494],\n",
              "       [0.6991603 ],\n",
              "       [0.5828842 ],\n",
              "       [0.5963719 ],\n",
              "       [0.6893008 ],\n",
              "       [0.4975858 ],\n",
              "       [0.6875959 ],\n",
              "       [0.6237638 ],\n",
              "       [0.72103405],\n",
              "       [0.75764394],\n",
              "       [0.7037956 ],\n",
              "       [0.56478846],\n",
              "       [0.6680422 ],\n",
              "       [0.75835586],\n",
              "       [0.66837066],\n",
              "       [0.69501746],\n",
              "       [0.64512074],\n",
              "       [0.53070855],\n",
              "       [0.558463  ],\n",
              "       [0.74254847],\n",
              "       [0.5378299 ],\n",
              "       [0.68786186],\n",
              "       [0.59509486],\n",
              "       [0.8328253 ],\n",
              "       [0.550222  ],\n",
              "       [0.5971514 ],\n",
              "       [0.59145707],\n",
              "       [0.6840274 ],\n",
              "       [0.76140755],\n",
              "       [0.72782433],\n",
              "       [0.62986183],\n",
              "       [0.59649324],\n",
              "       [0.59173673],\n",
              "       [0.64717877],\n",
              "       [0.54073834],\n",
              "       [0.5478621 ],\n",
              "       [0.7542622 ],\n",
              "       [0.7242205 ],\n",
              "       [0.5858143 ],\n",
              "       [0.67454815],\n",
              "       [0.6635684 ],\n",
              "       [0.72303736],\n",
              "       [0.67088985],\n",
              "       [0.61962396],\n",
              "       [0.67713827],\n",
              "       [0.44435993],\n",
              "       [0.67276776],\n",
              "       [0.60600215],\n",
              "       [0.6673108 ],\n",
              "       [0.7406509 ],\n",
              "       [0.7620261 ],\n",
              "       [0.6670286 ],\n",
              "       [0.7213172 ],\n",
              "       [0.69485164],\n",
              "       [0.7165891 ],\n",
              "       [0.72832036],\n",
              "       [0.76327586],\n",
              "       [0.7437978 ],\n",
              "       [0.6950054 ],\n",
              "       [0.58054733],\n",
              "       [0.6655283 ],\n",
              "       [0.55948585],\n",
              "       [0.6040478 ],\n",
              "       [0.43150043],\n",
              "       [0.7041286 ],\n",
              "       [0.72261775],\n",
              "       [0.56208503],\n",
              "       [0.6871433 ],\n",
              "       [0.6377853 ],\n",
              "       [0.5421036 ],\n",
              "       [0.59117305],\n",
              "       [0.6067289 ],\n",
              "       [0.7300105 ],\n",
              "       [0.5940881 ],\n",
              "       [0.673902  ],\n",
              "       [0.6634647 ],\n",
              "       [0.63966095],\n",
              "       [0.54604036],\n",
              "       [0.72104055],\n",
              "       [0.4969111 ],\n",
              "       [0.4964522 ],\n",
              "       [0.73826677],\n",
              "       [0.46755394],\n",
              "       [0.7242216 ],\n",
              "       [0.68575823],\n",
              "       [0.76997817],\n",
              "       [0.65230894],\n",
              "       [0.63119507],\n",
              "       [0.77192354],\n",
              "       [0.63945305],\n",
              "       [0.7866271 ],\n",
              "       [0.8182856 ],\n",
              "       [0.6210285 ],\n",
              "       [0.513378  ],\n",
              "       [0.66055304],\n",
              "       [0.6569992 ],\n",
              "       [0.709786  ],\n",
              "       [0.6558765 ],\n",
              "       [0.58036536],\n",
              "       [0.63993853],\n",
              "       [0.6031476 ],\n",
              "       [0.7160306 ],\n",
              "       [0.5296781 ],\n",
              "       [0.65832114],\n",
              "       [0.72371936],\n",
              "       [0.72089255],\n",
              "       [0.6038648 ],\n",
              "       [0.72788244],\n",
              "       [0.5459673 ],\n",
              "       [0.5971869 ],\n",
              "       [0.6378716 ],\n",
              "       [0.6815842 ],\n",
              "       [0.5887067 ],\n",
              "       [0.75523746],\n",
              "       [0.51888573],\n",
              "       [0.6019176 ],\n",
              "       [0.65963316],\n",
              "       [0.6125096 ],\n",
              "       [0.5731859 ],\n",
              "       [0.43209916],\n",
              "       [0.4991876 ],\n",
              "       [0.3941945 ],\n",
              "       [0.60693973],\n",
              "       [0.7394481 ],\n",
              "       [0.708177  ],\n",
              "       [0.48475146],\n",
              "       [0.6355897 ],\n",
              "       [0.64614236],\n",
              "       [0.6128855 ],\n",
              "       [0.7081048 ],\n",
              "       [0.68302095],\n",
              "       [0.6203228 ],\n",
              "       [0.6694945 ],\n",
              "       [0.52547807],\n",
              "       [0.6382127 ],\n",
              "       [0.63368225],\n",
              "       [0.65461254],\n",
              "       [0.67176384],\n",
              "       [0.5475793 ],\n",
              "       [0.7240235 ],\n",
              "       [0.52017504],\n",
              "       [0.67669684],\n",
              "       [0.6011464 ],\n",
              "       [0.5431687 ],\n",
              "       [0.6672343 ],\n",
              "       [0.773749  ],\n",
              "       [0.45529413],\n",
              "       [0.55208826],\n",
              "       [0.6370223 ],\n",
              "       [0.6945448 ],\n",
              "       [0.46106845],\n",
              "       [0.7123544 ],\n",
              "       [0.57198197],\n",
              "       [0.62921983],\n",
              "       [0.6486136 ],\n",
              "       [0.7621249 ],\n",
              "       [0.6994585 ],\n",
              "       [0.67403364],\n",
              "       [0.53332317],\n",
              "       [0.6924137 ],\n",
              "       [0.6913049 ],\n",
              "       [0.6354112 ],\n",
              "       [0.7295701 ],\n",
              "       [0.6836793 ],\n",
              "       [0.62489957],\n",
              "       [0.62469816],\n",
              "       [0.74421054],\n",
              "       [0.67860556],\n",
              "       [0.64574325],\n",
              "       [0.5744793 ],\n",
              "       [0.7221109 ],\n",
              "       [0.51873493],\n",
              "       [0.6141958 ],\n",
              "       [0.76819545],\n",
              "       [0.6347457 ],\n",
              "       [0.62099504],\n",
              "       [0.68740374],\n",
              "       [0.6745634 ],\n",
              "       [0.5537299 ],\n",
              "       [0.7511811 ],\n",
              "       [0.6082556 ],\n",
              "       [0.7041135 ],\n",
              "       [0.7652552 ],\n",
              "       [0.5479777 ],\n",
              "       [0.76970506],\n",
              "       [0.6752529 ],\n",
              "       [0.6311306 ],\n",
              "       [0.6299212 ],\n",
              "       [0.7299653 ],\n",
              "       [0.7394135 ],\n",
              "       [0.76296055],\n",
              "       [0.6416908 ],\n",
              "       [0.5528729 ],\n",
              "       [0.65045404],\n",
              "       [0.6885942 ],\n",
              "       [0.5881455 ],\n",
              "       [0.6456174 ],\n",
              "       [0.5014315 ],\n",
              "       [0.5842055 ],\n",
              "       [0.62494534],\n",
              "       [0.6419808 ],\n",
              "       [0.64583975],\n",
              "       [0.64448726],\n",
              "       [0.66782874],\n",
              "       [0.69078046],\n",
              "       [0.5884868 ],\n",
              "       [0.5565909 ],\n",
              "       [0.7061814 ],\n",
              "       [0.55730176],\n",
              "       [0.7035389 ],\n",
              "       [0.47620416],\n",
              "       [0.70272326],\n",
              "       [0.697289  ],\n",
              "       [0.71496   ],\n",
              "       [0.488063  ],\n",
              "       [0.5571771 ],\n",
              "       [0.61945504],\n",
              "       [0.79174745],\n",
              "       [0.733088  ],\n",
              "       [0.6849035 ],\n",
              "       [0.5855904 ],\n",
              "       [0.6230946 ],\n",
              "       [0.62268907],\n",
              "       [0.7099993 ],\n",
              "       [0.6654713 ],\n",
              "       [0.65025663],\n",
              "       [0.7671318 ],\n",
              "       [0.7386825 ],\n",
              "       [0.70258796],\n",
              "       [0.5857606 ],\n",
              "       [0.64558464],\n",
              "       [0.63170654],\n",
              "       [0.46473813],\n",
              "       [0.6875412 ],\n",
              "       [0.7310915 ],\n",
              "       [0.6053842 ],\n",
              "       [0.6555692 ],\n",
              "       [0.68610144],\n",
              "       [0.6449899 ],\n",
              "       [0.6091702 ],\n",
              "       [0.6273537 ],\n",
              "       [0.7995646 ],\n",
              "       [0.6195551 ],\n",
              "       [0.67422146],\n",
              "       [0.8200675 ],\n",
              "       [0.7079909 ],\n",
              "       [0.45218223],\n",
              "       [0.6792865 ],\n",
              "       [0.73017204],\n",
              "       [0.6566928 ],\n",
              "       [0.5303555 ],\n",
              "       [0.77142096],\n",
              "       [0.50405973],\n",
              "       [0.8003583 ],\n",
              "       [0.66341496],\n",
              "       [0.71907014],\n",
              "       [0.67225873],\n",
              "       [0.52884185],\n",
              "       [0.6764705 ],\n",
              "       [0.5619717 ],\n",
              "       [0.42940226],\n",
              "       [0.67496634],\n",
              "       [0.71947145],\n",
              "       [0.7172129 ],\n",
              "       [0.6186076 ],\n",
              "       [0.70688593],\n",
              "       [0.693104  ],\n",
              "       [0.78348553],\n",
              "       [0.56183094],\n",
              "       [0.6302208 ],\n",
              "       [0.5151141 ],\n",
              "       [0.5493874 ],\n",
              "       [0.7914476 ],\n",
              "       [0.5371568 ],\n",
              "       [0.7671582 ],\n",
              "       [0.7002502 ],\n",
              "       [0.72210157],\n",
              "       [0.665751  ],\n",
              "       [0.51075447],\n",
              "       [0.49109414],\n",
              "       [0.7343725 ],\n",
              "       [0.6293416 ],\n",
              "       [0.5865481 ],\n",
              "       [0.6100897 ],\n",
              "       [0.7328165 ],\n",
              "       [0.6107898 ],\n",
              "       [0.61694247],\n",
              "       [0.63750315],\n",
              "       [0.4427651 ],\n",
              "       [0.6519571 ],\n",
              "       [0.5930227 ],\n",
              "       [0.6642473 ],\n",
              "       [0.5316909 ],\n",
              "       [0.60540795],\n",
              "       [0.6460551 ],\n",
              "       [0.59434754],\n",
              "       [0.6787917 ],\n",
              "       [0.6840205 ],\n",
              "       [0.6518606 ],\n",
              "       [0.7373355 ],\n",
              "       [0.71013784],\n",
              "       [0.61559504],\n",
              "       [0.76205015],\n",
              "       [0.6717988 ],\n",
              "       [0.7302835 ],\n",
              "       [0.7651006 ],\n",
              "       [0.4532903 ],\n",
              "       [0.6795297 ],\n",
              "       [0.68887985],\n",
              "       [0.6170561 ],\n",
              "       [0.6842916 ],\n",
              "       [0.53861916],\n",
              "       [0.74252033],\n",
              "       [0.572283  ],\n",
              "       [0.50625956],\n",
              "       [0.71734154],\n",
              "       [0.77801365],\n",
              "       [0.53435266],\n",
              "       [0.45192733],\n",
              "       [0.6615735 ],\n",
              "       [0.76428825],\n",
              "       [0.78633404],\n",
              "       [0.7155249 ],\n",
              "       [0.58422077],\n",
              "       [0.65453523],\n",
              "       [0.60835135],\n",
              "       [0.56714046],\n",
              "       [0.44956797],\n",
              "       [0.7102955 ],\n",
              "       [0.60114783]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}